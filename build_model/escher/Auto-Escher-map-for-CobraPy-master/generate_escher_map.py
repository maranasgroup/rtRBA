from __future__ import print_function
__author__ = 'JCThomas - jaytee00@gmail.com'
version = '0.1'
#import cobra, cobra.test
import escher_map
from escher_map import Metabolite
from collections import OrderedDict

node_id_counter = 0

selected_model = None


__doc__ = \
"""
Call gen_map() passing the Cobra model, a list of
the reactions you wish to include and a list of metabolites you do
not wish to be used to create links between reactions (e.g. ATP). This
returns an EscherMap object. Use map_obj.dump_json() to get a JSON that
can be passed to escher.Builder()

The layout of the metabolites is produced by the igraph module using the
Fruchterman-Reingold force-directed algorithm. It may be possible to alter
the settings in the assign_positions() function; see the IGraph documentation
for more info. http://igraph.org/python/

Requires cobra, escher, igraph, json and prerequisites for those packages.

Known issues:
- Reactions that share the same primary metabolites are layed over the top of
each other and can end up with secondary metabolites further away.
- Unlinked reactions are doubled for some reason
- Label placing could be better
- unnecesary midnodes

"""


def map_links(reactions_of_interest,common_intermediates,
             reverse_map = False, verbose = False,
             ):
    """Returns a dictionary where keys are reactions and values are a list of
     reactions that consume a metbolite produced by the key reaction.

     Metabolites specified in the list common_intermediates are not used to
     make links, so reactions that share only common intermediates will not
     be paired in the dictionary."""

    # If reactionA produces a (non-common) metabolite used in reactionB then
    # reactionA should have the index of reactionB.
    # The met in rA will have a stoich +n and rB -m
    lmap = OrderedDict([(r, []) for r in reactions_of_interest])

    if reverse_map:
        r_lmap = OrderedDict([(r, []) for r in reactions_of_interest])

    # identify reactions linked by a shared metabolite
    for current_r in reactions_of_interest:
        for other_r in reactions_of_interest:
            if other_r is not current_r:
                for current_m in current_r.metabolites:
                    if current_m not in common_intermediates and\
                        current_m in other_r.metabolites.keys():
                        # At this point we have two reactions with the same metabolite,
                        # test the direction of the reaction.
                        if current_r.metabolites[current_m] > 0 > other_r.metabolites[current_m]:
                            lmap[current_r].append(other_r)
                        elif reverse_map and current_r.metabolites[current_m] \
                                < 0 < other_r.metabolites[current_m]:
                            r_lmap[current_r].append(other_r)
    if verbose:
        print('Of', len(lmap.keys()), 'reactions', len([r for r in lmap.values() if r != []]), 'have a link' )
        all_values = []
        for li in lmap.values():
            for v in li:
                all_values.append(v)
        unlinked_to = 0
        print('The following are only connected to other reactions by common intermediates')
        for r in lmap:
            if lmap[r] == [] and r not in all_values:
                unlinked_to +=1
                print('%s [%s]::  %s'%(r.name, r.id, r.reaction))
        print('Unconnected count = ', unlinked_to)
    if reverse_map:
        return lmap, r_lmap
    return lmap

def assign_positions(metabolites_, scale = 200):
    """returns a list of metabolites with grid_xy generated by a graph plotting
    algorythm and connections using node_id in the first position. Increasing
    scale spreads things out.

    The layout of the metabolites is produced by the IGraph module using the
    Fruchterman-Reingold force-directed algorithm with default settings. It
    is likely possible to alter these settings to improve results;
    see the IGraph documentation for more info http://igraph.org/python/"""
    import igraph
    metabolites = metabolites_[:]
    primary_mets = [m for m in metabolites if m.primary]


    # Using a graphing algorithm to lay stuff out, needs a dictionary of node connections
    met_by_node_id = dict([(m.node_id, m) for m in metabolites])

    # This uses a tuple of the metabolite node ids to record the reaction they are involved in
    # First string the node that records the .connection
    reaction_pairs = {}

    # All node ids for iterating over later
    metidset = set()

    # Go through the primary metabolites and put them into the plotting algorithm
    # Secondary metabolites will be placed later relative to the primary metabolites.
    # First put all mets in the dictionaries and change the connection format.
    for met in metabolites:
        if met.connections:
            for con_i, conn in enumerate(met.connections):
                if met in primary_mets:
                    to_id, from_id = r_pair = met.node_id, conn.node_id
                    if r_pair in reaction_pairs:
                        reaction_pairs[r_pair].append(conn.reaction_name)
                    else:
                        reaction_pairs[r_pair] = [conn.reaction_name]
                    metidset.add(to_id)
                    metidset.add(from_id)
        else:
            # There shouldnt be anything that is unconncted here but just in case
            metidset.add(met.node_id)

    # Populate the Graph with metabolites and add connections
    metgraph = igraph.Graph()
    for metid in metidset:
        metgraph.add_vertex(metid)
    for from_id, to_id in reaction_pairs.keys():
        metgraph.add_edge(from_id, to_id)

    # Get the layout. Vertexes coords in layo.coords, index of coords matches metgraph.vs
    layo = metgraph.layout('fr')

    # Get the mean distance between vertex for scaling
    # (they seem to vary a lot depending on the number of vertexes).
    # Also get the deplacement xy for each vertex pair. Value used to place secondary mets
    diffs = []
    vertx_displacement = {}
    # vert_index used to go from metid in metgraph to vertex in layo.coords
    vert_index = dict([(list(vert.attributes().values())[0], i)
                       for i, vert in enumerate(metgraph.vs)])

    # Node ids
    for from_id, to_id in reaction_pairs.keys():
        # get index positions of vertex info
        fromi, toi = vert_index[from_id], vert_index[to_id]
        fromxy, toxy = layo.coords[fromi], layo.coords[toi]
        # psuedo distance for scaling.
        diffs.append(sum([abs(fromxy[n]-toxy[n]) for n in (0, 1)]))
        # Get the displacement values.
        for r in reaction_pairs[(from_id, to_id)]:
            # Adding the displacemnt value to the vertx_xy will give you the coords for its target
            vertx_displacement[(to_id, r)] = [fromxy[n]-toxy[n] for n in (0, 1)]
            vertx_displacement[(from_id, r)] = [toxy[n]-fromxy[n] for n in (0, 1)]

    mean_diff = sum(diffs)/len(diffs)
    scaling_factor = mean_diff/scale

    # Assign the vertex coords to the metabolite objects
    for i, vert in enumerate(metgraph.vs):
        #print(vert.attributes())
        node_id = list(vert.attributes().values())[0]
        met_obj = met_by_node_id[node_id]
        met_obj.grid_xy = layo.coords[i]

    # Place secondary nodes. should be between the midnode and the metabolite node
    # that is; between 1/9, 2/9 of the distance along the line towards the other node and
    # a similar distance away from the line.
    # This is achieved by getting a 1/9 displacement value. The 4 positions each side of the line
    # are determined using multiples of these xy values
    occupied_pos = [tuple(m.grid_xy) for m in metabolites if m in primary_mets]
    #print(occupied_pos)
    secondary_mets = [m for m in metabolites if not m.primary]
    #[print(m) for m in secondary_mets]
    for met in secondary_mets:
        if met.connections:
            # Secondary metabolites should only have one connection but just in case...
            for conn in met.connections:
                if not conn.direct:
                    # Get the potential side positions in
                    target = met_by_node_id[conn.node_id]
                    x, y = target.grid_xy
                    if (target.node_id, conn.reaction_name) in vertx_displacement.keys():
                        full_displacement = vertx_displacement[(target.node_id, conn.reaction_name)]
                        # get the 1 9th displacement values
                        dx, dy = [full_displacement[n]/9 for n in (0, 1)]
                        dy *= 2
                        # The n*m potential side postions
                        side_positions = []

                        for n in (1, 2, 3, 4, 5):
                            for m in (1, 2, 3):
                                side_positions.append((x + m*dx - n*dy,   y + m*dy + n*dx))

                        # Find an unoccupied position and occupy it
                        for pos in side_positions:
                            if pos not in occupied_pos:
                                met.grid_xy = pos
                                occupied_pos.append(pos)
                                break
                        else:
                            raise ValueError("Couldn't find position for side met")
                    else:
                        print('No vert displacement:',target.name, conn.reaction_name)

    # Scale em
    for met in metabolites:
        met.grid_xy = tuple([met.grid_xy[n]/scaling_factor for n in (0, 1)])

    return metabolites

def getm(metabolite_id, model = selected_model):
    """give cobra id string, get cobra metabolite.
    Set selected_model global var for convenience."""
    if model is None:
        print('Set selected_model global or pass a model as an arg.')
        return
    return model.metabolites.get_by_id(metabolite_id)


def getr(reaction_id, model = selected_model):
    """give cobra id string, get cobra reaction.
    Set selected_model global var for convenience."""
    if model is None:
        print('Set selected_model or pass a model as an arg.')
        return
    return model.reactions.get_by_id(reaction_id)

def generate_met_obj(reaction_link_map, metabolite_count):
    """Creates primary Metabolite objects for the two least frequently occuring
    metabolites in a reaction and secondary Metabolite objs for the other mets.
    Connects metabolite objects.

    The primary/secondary distinction is used by assign_positions() and
    escher_map.py when making the map."""
    global node_id_counter

    def get_least_common(metlist):
        metlist.sort(key = lambda m: m.id) # So the same model will return the same met every time
        metlist.sort(key = lambda m: metabolite_count[m])
        if len(metlist):
            return metlist[0]
        else:
            return None

    primary_met_bin = OrderedDict()
    processed_reactions = []

    # Go through the reactions generating the metabolites that link the reaction pairs
    # and adding metabolite connections to any uncommon products of the second reaction
    # in the pair
    # Will need to go through and add the metabolites of source reactions seperately
    for r in reaction_link_map:
        targ_reactions = reaction_link_map[r]
        if targ_reactions:
            for targ_r in targ_reactions:
                # Get the mets that link the reactions
                linking_mets = [m for m in r.products if m in targ_r.reactants]
                if not linking_mets:
                    raise ValueError("reactions don't actually link?", r.id, targ_r.id)
                elif len(linking_mets) > 1:
                    # Sort by name then occurence to get the least commonly occuring met
                    linking_mets.sort(key = lambda m: m.id)
                    linking_mets.sort(key = lambda m: metabolite_count[m])

                c_met = linking_mets[0]

                # Create the met if it doesn't already exist
                if c_met.id not in primary_met_bin.keys():
                    met = Metabolite(c_met.id, 'n' + str(node_id_counter), c_met)
                    node_id_counter +=1
                    primary_met_bin[met.name] = met
                else:
                    met = primary_met_bin[c_met.id]

                # Add a link to the least common product of the target reaction,
                # creating the Metabolite obj if not already there
                conn_mets = [m for m in targ_r.products]
                if conn_mets: # False in the case of sink reactions
                    conn_c_met = get_least_common(conn_mets)

                    # connected to met created if not already
                    if conn_c_met and conn_c_met.id not in primary_met_bin:
                        conn_e_met = Metabolite(conn_c_met.id, 'n' + str(node_id_counter), conn_c_met)
                        node_id_counter +=1
                        primary_met_bin[conn_e_met.name] = conn_e_met
                    else:
                        conn_e_met = primary_met_bin[conn_c_met.id]

                    met.add_connection(conn_e_met.node_id, conn_e_met.name, True, targ_r.id)
                processed_reactions.append(targ_r)


    # I think the only things that shouldn't end up in processed_r are source reactions
    # that contain uncommon reactants not produced in any other reaction
    for source_r in [_r for _r in reaction_link_map.keys() if _r not in processed_reactions]:
        reactants = [m for m in source_r.reactants]
        primary_reactant = get_least_common(reactants)
        if primary_reactant and primary_reactant.id not in primary_met_bin:
            source_met = Metabolite(primary_reactant.id, 'n' + str(node_id_counter),
                                    primary_reactant)
            node_id_counter +=1
            primary_met_bin[source_met.name] = source_met
        else:
            source_met = primary_met_bin[primary_reactant.id]
        products = [m for m in source_r.products]
        primary_prod = get_least_common(products)
        if primary_prod:
            if primary_prod.id not in primary_met_bin:
                prod = Metabolite(primary_prod.id, 'n' + str(node_id_counter), primary_prod)
                node_id_counter +=1
                primary_met_bin[prod.name] = prod
            else:
                prod = primary_met_bin[primary_prod.id]

            source_met.add_connection(prod.node_id, prod.name, True, source_r.id)

    # Now add secondaries
    # Get all reactions by name
    all_reactions = {}
    for r in reaction_link_map.keys():
        all_reactions[r.id] = r
        for targr in reaction_link_map[r]:
            all_reactions[targr.id] = targr

    secondary_mets = []
    for met in primary_met_bin.values():
        if met.connections:
            for conn in met.connections:
                # substrates connect to met, products connect to met.connection[n].met_name
                substrates = [m for m in all_reactions[conn.reaction_name].reactants
                              if m.id != met.name]
                products   = [m for m in all_reactions[conn.reaction_name].products
                              if m.id != conn.met_name]
                if substrates:
                    for sub in substrates:
                        sub_esch_met = Metabolite(sub.id, 'n' + str(node_id_counter),
                                                  sub, primary=False)
                        node_id_counter +=1
                        sub_esch_met.add_connection(met.node_id,met.name,False,conn.reaction_name)
                        secondary_mets.append(sub_esch_met)
                if products:
                    for prod in products:
                        p = Metabolite(prod.id,'n' + str(node_id_counter),
                                       prod, primary = False)
                        node_id_counter+=1
                        p.add_connection(conn.node_id,conn.met_name,False, conn.reaction_name)
                        secondary_mets.append(p)

    return list(primary_met_bin.values())+secondary_mets


def metabolite_occurence(reactions_of_interest):
    """Returns a dictionary giving the number of occurences of each metabolite
    in the reactions"""

    met_occurence = {}

    for r in reactions_of_interest:
        for m in r.metabolites:
            if m not in met_occurence.keys():
                met_occurence[m]  = 1
            else:
                met_occurence[m] += 1
    return met_occurence

def gen_map(model, reactions_of_interest, common_intermediates,
             scale = 350, metabolite_count = None,get_positions = True):
    """Return a escher_map.EscherMap object if get_positions is True.
    Return metabolite objects with no set .grid_xy if get_positions is False.

    Increasing scale will magnify the distances on the Escher canvas.

    Requires a cobra model, a list of reactions to include on the map,
    and a list of common intermediates that will not be used to link
    reactions.

    Uses generate_met_obj() and  assign_positions() and escher_map.py

    metabolite_count is gotten automatically if not supplied"""

    if len(reactions_of_interest) == 0:
        raise ValueError('No reactions specified.')

    reaction_links = map_links(reactions_of_interest, common_intermediates, verbose=True)
    if metabolite_count is None:
        metabolite_count = metabolite_occurence(reactions_of_interest)

    met_obj = generate_met_obj(reaction_links,metabolite_count)
    if not get_positions:
        return met_obj

    placed_met_obj = assign_positions(met_obj, scale)

    # Filter out reactions that didnt get connections
    connected_reactions = []
    for m in placed_met_obj:
        if m.connections:
            for con in m.connections:
                connected_reactions.append(con.reaction_name)
    connected_reactions = [r for r in reactions_of_interest if r.id in connected_reactions]

    # Get the EscherMap object
    escmap = escher_map.EscherMap(model, connected_reactions, placed_met_obj, 1)
    escmap.generate_nodes_and_segments()
    return escmap

